"""
Custom Text Reconstruction Pipeline (Î Î±ÏÎ±Î´Î¿Ï„Î­Î¿ 1A)
Implements a rule-based approach to text reconstruction
"""

import re
import string
from typing import List, Dict, Tuple
import logging
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ReconstructionResult:
    """Data class for reconstruction results"""
    original: str
    reconstructed: str
    corrections: List[str]
    confidence_score: float
    processing_steps: List[str]


class CustomTextReconstructor:
    """
    Custom rule-based text reconstruction pipeline

    This class implements a custom approach to text reconstruction using:
    - Grammar rules
    - Common error patterns
    - Linguistic heuristics
    - Context-aware corrections
    """

    def __init__(self):
        self.processing_steps = []
        self.initialize_rules()

    def initialize_rules(self):
        """Initialize grammar rules and error patterns"""

        # Common grammar corrections
        self.grammar_rules = {
            # Article corrections
            r'\ba\s+([aeiouAEIOU])': r'an \1',  # a apple -> an apple

            # Verb form corrections
            r'\bto\s+celebrate\s+it\s+with\s+all\s+safe': 'to celebrate safely',
            r'\bThank\s+your\s+message': 'Thank you for your message',
            r'\bI\s+am\s+very\s+appreciated': 'I very much appreciate',

            # Preposition corrections
            r'\bto\s+show\s+our\s+words\s+to\s+the\s+doctor': 'to convey our message to the doctor',
            r'\bas\s+his\s+next\s+contract\s+checking': 'for his next contract review',

            # Tense and aspect corrections
            r'\bDuring\s+our\s+ï¬nal\s+discuss': 'During our final discussion',
            r'\bwe\s+were\s+waiting\s+since': 'we had been waiting since',
            r'\bthe\s+updates\s+was\s+confusing': 'the updates were confusing',
            r'\bas\s+it\s+not\s+included': 'as they did not include',

            # Word choice and clarity
            r'\balthough\s+bit\s+delay': 'although there was some delay',
            r'\band\s+less\s+communication\s+at\s+recent\s+days': 'and less communication in recent days',
            r'\bthey\s+really\s+tried\s+best': 'they really tried their best',
            r'\bfor\s+paper\s+and\s+cooperation': 'for the paper and collaboration',

            # Sentence structure improvements
            r'\buntil\s+the\s+Springer\s+link\s+came\s+ï¬nally': 'until the Springer publication finally came',
            r'\bif\s+the\s+doctor\s+still\s+plan\s+for': 'if the doctor still plans for',
            r'\bbefore\s+he\s+sending\s+again': 'before sending it again',
            r'\bI\s+didn\'t\s+see\s+that\s+part\s+ï¬nal\s+yet': 'I haven\'t seen the final version of that part yet',

            # Word corrections
            r'\bï¬nal\b': 'final',
            r'\beï¬€orts\b': 'efforts',
            r'\bcoï¬€ee\b': 'coffee',
        }

        # Punctuation rules
        self.punctuation_rules = {
            # Add missing commas
            r'(\w+)\s+(and|but|or)\s+(\w+)': r'\1, \2 \3',
            # Fix spacing around punctuation
            r'\s+([.!?,:;])': r'\1',
            r'([.!?])\s*([A-Z])': r'\1 \2',
            # Fix quotation marks
            r'"\s*([^"]+)\s*"': r'"\1"',
        }

        # Word replacement dictionary
        self.word_replacements = {
            'ï¬nal': 'final',
            'eï¬€orts': 'efforts',
            'coï¬€ee': 'coffee',
            'discuss': 'discussion',
            'appreciated': 'appreciate',
            'plan': 'plans',
            'sending': 'send',
        }

        # Context-aware phrase replacements
        self.phrase_replacements = {
            'to celebrate it with all safe and great in our lives':
                'to celebrate safely and joyfully in our lives',
            'Hope you too, to enjoy it as my deepest wishes':
                'I hope you too will enjoy it, with my deepest wishes',
            'Thank your message to show our words to the doctor':
                'Thank you for your message conveying our words to the doctor',
            'as his next contract checking, to all of us':
                'regarding his next contract review for all of us',
            'I got this message to see the approved message':
                'I received this message to see the approved content',
            'to show me, this, a couple of days ago':
                'showing me this a couple of days ago',
            'I am very appreciated the full support':
                'I very much appreciate the full support',
        }

    def apply_grammar_rules(self, text: str) -> Tuple[str, List[str]]:
        """Apply grammar correction rules"""
        corrections = []
        result = text

        for pattern, replacement in self.grammar_rules.items():
            if re.search(pattern, result):
                old_result = result
                result = re.sub(pattern, replacement, result)
                if old_result != result:
                    corrections.append(
                        f"Grammar: '{pattern}' -> '{replacement}'")

        return result, corrections

    def apply_punctuation_rules(self, text: str) -> Tuple[str, List[str]]:
        """Apply punctuation correction rules"""
        corrections = []
        result = text

        for pattern, replacement in self.punctuation_rules.items():
            if re.search(pattern, result):
                old_result = result
                result = re.sub(pattern, replacement, result)
                if old_result != result:
                    corrections.append(
                        f"Punctuation: '{pattern}' -> '{replacement}'")

        return result, corrections

    def apply_word_replacements(self, text: str) -> Tuple[str, List[str]]:
        """Apply word-level replacements"""
        corrections = []
        result = text

        for old_word, new_word in self.word_replacements.items():
            pattern = r'\b' + re.escape(old_word) + r'\b'
            if re.search(pattern, result, re.IGNORECASE):
                old_result = result
                result = re.sub(pattern, new_word, result, flags=re.IGNORECASE)
                if old_result != result:
                    corrections.append(
                        f"Word replacement: '{old_word}' -> '{new_word}'")

        return result, corrections

    def apply_phrase_replacements(self, text: str) -> Tuple[str, List[str]]:
        """Apply phrase-level replacements"""
        corrections = []
        result = text

        for old_phrase, new_phrase in self.phrase_replacements.items():
            if old_phrase.lower() in result.lower():
                # Find the exact case and position
                pattern = re.escape(old_phrase)
                if re.search(pattern, result, re.IGNORECASE):
                    old_result = result
                    result = re.sub(pattern, new_phrase,
                                    result, flags=re.IGNORECASE)
                    if old_result != result:
                        corrections.append(
                            f"Phrase replacement: '{old_phrase}' -> '{new_phrase}'")

        return result, corrections

    def improve_sentence_structure(self, text: str) -> Tuple[str, List[str]]:
        """Improve overall sentence structure"""
        corrections = []
        result = text

        # Split into sentences for better processing
        sentences = re.split(r'[.!?]+', result)
        improved_sentences = []

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            improved = sentence

            # Ensure proper capitalization
            if improved and not improved[0].isupper():
                improved = improved[0].upper() + improved[1:]
                corrections.append(f"Capitalization: First letter of sentence")

            # Remove extra spaces
            old_improved = improved
            improved = re.sub(r'\s+', ' ', improved)
            if old_improved != improved:
                corrections.append(f"Spacing: Removed extra spaces")

            # Fix common structural issues
            if 'I told him about the new submission â€” the one we were waiting' in improved:
                improved = improved.replace(
                    'the one we were waiting since last autumn',
                    'the one we had been waiting for since last autumn'
                )
                corrections.append("Structure: Fixed temporal reference")

            improved_sentences.append(improved)

        result = '. '.join(improved_sentences)
        if not result.endswith('.'):
            result += '.'

        return result, corrections

    def calculate_confidence_score(self, original: str, reconstructed: str,
                                   corrections: List[str]) -> float:
        """Calculate confidence score for the reconstruction"""

        # Base score
        score = 0.5

        # Increase score based on number of corrections made
        score += min(len(corrections) * 0.05, 0.3)

        # Increase score if text length is reasonable
        if 50 <= len(reconstructed) <= 500:
            score += 0.1

        # Check for common good indicators
        good_indicators = [
            'proper capitalization',
            'correct grammar',
            'clear meaning',
            'good flow'
        ]

        # Simple heuristics for quality
        if reconstructed.count('.') > 0:  # Has proper sentence endings
            score += 0.05

        if len(reconstructed.split()) > len(original.split()) * 0.8:  # Not too much shrinkage
            score += 0.05

        # Penalize if too many corrections (might indicate over-processing)
        if len(corrections) > 10:
            score -= 0.1

        return min(max(score, 0.0), 1.0)

    def reconstruct_sentence(self, sentence: str) -> ReconstructionResult:
        """
        Reconstruct a single sentence using the custom pipeline

        Args:
            sentence: Original sentence to reconstruct

        Returns:
            ReconstructionResult object with all processing information
        """
        logger.info(f"ðŸ”§ Reconstructing sentence: {sentence[:50]}...")

        original = sentence
        result = sentence
        all_corrections = []
        processing_steps = []

        # Step 1: Apply phrase replacements (highest priority)
        result, corrections = self.apply_phrase_replacements(result)
        all_corrections.extend(corrections)
        if corrections:
            processing_steps.append("Applied phrase replacements")

        # Step 2: Apply grammar rules
        result, corrections = self.apply_grammar_rules(result)
        all_corrections.extend(corrections)
        if corrections:
            processing_steps.append("Applied grammar rules")

        # Step 3: Apply word replacements
        result, corrections = self.apply_word_replacements(result)
        all_corrections.extend(corrections)
        if corrections:
            processing_steps.append("Applied word replacements")

        # Step 4: Fix punctuation
        result, corrections = self.apply_punctuation_rules(result)
        all_corrections.extend(corrections)
        if corrections:
            processing_steps.append("Applied punctuation rules")

        # Step 5: Improve sentence structure
        result, corrections = self.improve_sentence_structure(result)
        all_corrections.extend(corrections)
        if corrections:
            processing_steps.append("Improved sentence structure")

        # Calculate confidence score
        confidence = self.calculate_confidence_score(
            original, result, all_corrections)

        reconstruction_result = ReconstructionResult(
            original=original,
            reconstructed=result,
            corrections=all_corrections,
            confidence_score=confidence,
            processing_steps=processing_steps
        )

        logger.info(
            f"âœ… Reconstruction completed with confidence: {confidence:.2f}")
        return reconstruction_result

    def reconstruct_sentences(self, sentences: List[str]) -> Dict[str, ReconstructionResult]:
        """
        Reconstruct multiple sentences using the custom pipeline

        Args:
            sentences: List of sentences to reconstruct

        Returns:
            Dictionary mapping sentence index to ReconstructionResult
        """
        logger.info(
            f"ðŸš€ Starting custom reconstruction for {len(sentences)} sentences")

        results = {}

        for i, sentence in enumerate(sentences):
            logger.info(f"ðŸ“ Processing sentence {i+1}/{len(sentences)}")

            result = self.reconstruct_sentence(sentence)
            results[f"sentence_{i+1}"] = result

            # Log the result for debugging
            logger.info(f"Original: {result.original}")
            logger.info(f"Reconstructed: {result.reconstructed}")
            logger.info(f"Corrections: {len(result.corrections)}")
            logger.info(f"Confidence: {result.confidence_score:.2f}")
            logger.info("---")

        logger.info(f"âœ… Custom reconstruction completed for all sentences")
        return results

    def get_reconstruction_summary(self, results: Dict[str, ReconstructionResult]) -> Dict:
        """
        Generate a summary of reconstruction results

        Args:
            results: Dictionary of reconstruction results

        Returns:
            Summary dictionary with statistics and analysis
        """
        total_sentences = len(results)
        total_corrections = sum(len(result.corrections)
                                for result in results.values())
        avg_confidence = sum(
            result.confidence_score for result in results.values()) / total_sentences

        # Count correction types
        correction_types = {}
        for result in results.values():
            for correction in result.corrections:
                correction_type = correction.split(':')[0]
                correction_types[correction_type] = correction_types.get(
                    correction_type, 0) + 1

        # Processing steps frequency
        step_frequency = {}
        for result in results.values():
            for step in result.processing_steps:
                step_frequency[step] = step_frequency.get(step, 0) + 1

        summary = {
            'total_sentences': total_sentences,
            'total_corrections': total_corrections,
            'average_confidence': avg_confidence,
            'correction_types': correction_types,
            'processing_steps_frequency': step_frequency,
            'methodology': 'Custom rule-based pipeline with grammar rules, word replacements, and structural improvements'
        }

        return summary
